{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "YhqXxpamFARq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/handson_srm/s1"
      ],
      "metadata": {
        "id": "td9p_9osvr5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages"
      ],
      "metadata": {
        "id": "pTN7o73CxpU0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NoduTJIqEvv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess inputs"
      ],
      "metadata": {
        "id": "k8Qbwuzdx0dH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,)),])"
      ],
      "metadata": {
        "id": "5lFD-xj8qWVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ToTensor()\n",
        " - converts the image with a pixel range of [0, 255] to a PyTorch FloatTensor of shape (C, H, W) with a range [0.0, 1.0]"
      ],
      "metadata": {
        "id": "3xeJCeo3yE9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize() \n",
        "- output[channel] = (input[channel] - mean[channel]) / std[channel]\n",
        "\n",
        "- Normalization helps get data within a range and reduces the skewness which helps learn faster and better. \n",
        "- Normalization can also tackle the diminishing and exploding gradients problems."
      ],
      "metadata": {
        "id": "1uzgtjA4xCnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Dataloaders"
      ],
      "metadata": {
        "id": "7dZes3DQzlsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Combines a dataset and a sampler\n",
        "- Provides an iterable over the given dataset\n",
        "- The DataLoader supports both map-style and iterable-style datasets - - - Supports with single- or multi-process loading\n",
        "- Customizing loading order\n",
        "- Automatic batching"
      ],
      "metadata": {
        "id": "p_oL6gEw01fO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = datasets.MNIST('trainset', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "i1AcwXIMqY7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valset = datasets.MNIST('testset', download=True, train=False, transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "v-258nSWz5i9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)"
      ],
      "metadata": {
        "id": "nDZYc7_xz-tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have an iterator, let's visualize our data"
      ],
      "metadata": {
        "id": "7Cxx5qFSCMdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = dataiter.next()"
      ],
      "metadata": {
        "id": "J9Qg2ipB0Acv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "id": "MVoe0YEL0Dtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(images[2].numpy().squeeze(), cmap='gray_r')"
      ],
      "metadata": {
        "id": "rTOnzN15uaN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure()\n",
        "total_samples = 8\n",
        "for index in range(1,total_samples+1):\n",
        "    plt.subplot(2, 4, index)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(images[index-1].numpy().squeeze(), cmap='gray_r')"
      ],
      "metadata": {
        "id": "NBvtMO96ud6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "9u1I-5qDGiQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_labels = nn.functional.one_hot(labels, num_classes=10)"
      ],
      "metadata": {
        "id": "qr_TSdxjGo5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_labels"
      ],
      "metadata": {
        "id": "nj2vbCqGG53K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's build our DNN"
      ],
      "metadata": {
        "id": "wCn3pKjc_iTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.Softmax(dim=1))"
      ],
      "metadata": {
        "id": "hhmBR2QCurzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "ujZRzrUDu2yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Untrained Inference"
      ],
      "metadata": {
        "id": "NfSyK7w6_7Ba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets flatten the images to a 1D array/tensor"
      ],
      "metadata": {
        "id": "8-jZcd6bFBzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_inputs = images.view(images.shape[0], -1)\n",
        "model_inputs.shape"
      ],
      "metadata": {
        "id": "JQ8REqFpEfWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs = model(model_inputs) # probabilities\n",
        "pred_probs.shape"
      ],
      "metadata": {
        "id": "U0BNqhftA2WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs"
      ],
      "metadata": {
        "id": "2P4X4ggcH3__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs.sum(dim=-1)"
      ],
      "metadata": {
        "id": "T_sl7-0-BSMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')"
      ],
      "metadata": {
        "id": "oJBGGVn2HZPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[0]"
      ],
      "metadata": {
        "id": "x7Rq1b7CFffH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_labels[0]"
      ],
      "metadata": {
        "id": "h3Y6AxlxHFZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs[0]"
      ],
      "metadata": {
        "id": "6TMBNlKDFaNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argmax(pred_probs[0], dim=-1)"
      ],
      "metadata": {
        "id": "pnQV51wWICMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "-6gzqPyVIYcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argmax(pred_probs, dim=0)"
      ],
      "metadata": {
        "id": "VslLn44lIafp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(pred_probs, labels) #calculate the NLL loss"
      ],
      "metadata": {
        "id": "azb9fXuwuyus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "id": "vWbA2mQHLLkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "loss.backward()\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ],
      "metadata": {
        "id": "ylVy7ZxULhKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "time_init = time()\n",
        "epochs = 15\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "    \n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        #This is where the model learns by backpropagating\n",
        "        loss.backward()\n",
        "        \n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
        "print(\"\\nTraining Time (in minutes) =\",(time()-time_init)/60)"
      ],
      "metadata": {
        "id": "2wXACm0PN1eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(valloader))\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred_probs = model(images.view(images.shape[0], -1))\n",
        "\n",
        "torch.argmax(pred_probs, dim=-1)"
      ],
      "metadata": {
        "id": "8Hq8lOWPaT42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs"
      ],
      "metadata": {
        "id": "UfGjJk_Ga4Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predicted Digit =\", torch.argmax(pred_probs[0], dim=-1))"
      ],
      "metadata": {
        "id": "GsrexeF1bUJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "tiVEqUWAbbQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7iABNzBUbks8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bI9Jy0Qjbkau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# correct_count, all_count = 0, 0\n",
        "# for images,labels in valloader:\n",
        "#   for i in range(len(labels)):\n",
        "#     img = images[i].view(1, 784)\n",
        "#     with torch.no_grad():\n",
        "#         logps = model(img)\n",
        "\n",
        "    \n",
        "#     ps = torch.exp(logps)\n",
        "#     probab = list(ps.numpy()[0])\n",
        "#     pred_label = probab.index(max(probab))\n",
        "#     true_label = labels.numpy()[i]\n",
        "#     if(true_label == pred_label):\n",
        "#       correct_count += 1\n",
        "#     all_count += 1\n",
        "\n",
        "# print(\"Number Of Images Tested =\", all_count)\n",
        "# print(\"\\nModel Accuracy =\", (correct_count/all_count))"
      ],
      "metadata": {
        "id": "kkp0-1eYOhi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, './my_mnist_model.pt') "
      ],
      "metadata": {
        "id": "QhHawmdMOqwC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}